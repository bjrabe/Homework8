---
title: "Homework 8"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## Loading Packages

First we load all packages which will be needed for this assignment.

```{r}
library(tidyverse)
library(tidymodels)
library(matrixStats)
library(ggcorrplot)
```


## Reading Data

Next we read in the data.

```{r}
rentals <- read_csv('https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv', locale=locale(encoding="latin1"))
```


## EDA

Now we perform some exploratory data analysis.

Step 1. In this step, we check our imported tibble for missing data.

```{r}
colSums(is.na(rentals))
```

We see from the output that there are no missing values in any of the columns.

Steps 2 through 4. We combine steps 2 through 4. First, we check the data type for each column. We first print the tibble to view this.

```{r}
rentals
```

We note that the date is in character form, which is not ideal. We fix this now by using the lubridate package to transform the date column into Date-type data. 

```{r}
rentals <- rentals |>
  mutate(Date = dmy(Date))
```


Reviewing the data description, the quantitative variables appear to be Rented Bike Count, Hour, Temperature, Humidity, Wind speed, Visibility, Dew point temperature, Solar Radiation, Rainfall, and Snowfall. All of these quantitative variables are already stored as doubles, so we don't need to make a change here. We will view their summary stats to make sure the numbers make sense. Note `range.1` is the minimum and `range.2` is the maximum, respectively, of an observation. 

```{r}
rentals_numeric <- rentals |>
  select(where(is.numeric)) |>
  as.matrix()

data.frame('mean' = colMeans(rentals_numeric),
'median' = colMedians(rentals_numeric),
'sd' = colSds(rentals_numeric),
'IQR' = colIQRs(rentals_numeric),
'range' = colRanges(rentals_numeric)) |>
  round(1) 

```

Looking at the summary statistics for numeric variables, all of the results appear appropriate for what they represent.

The categorical variables appear to be Seasons, Holiday, and Functioning Day. They are stored as data type character. We convert them to factors. 

```{r}
rentals <- rentals |>
  mutate(Seasons = as.factor(Seasons),
         Holiday = as.factor(Holiday),
         `Functioning Day` = as.factor(`Functioning Day`))
```

Now it is easy to check the unique values and counts for the categorical variables. 

```{r}
rentals |>
  select(where(is.factor)) |>
  summary()
```


Step 5. In this step, we rename the variables so they have easy to use names which follow R naming conventions.

```{r}
rentals <- rentals |>
  rename('date' = 'Date',
         'rented_bike_count' = 'Rented Bike Count',
         'hour' = 'Hour',
         'temperature' = 'Temperature(°C)',
         'humidity' = 'Humidity(%)',
         'wind_speed' = 'Wind speed (m/s)',
         'visibility' = 'Visibility (10m)',
         'dew_point_temp' = 'Dew point temperature(°C)',
         'solar_radiation' = 'Solar Radiation (MJ/m2)',
         'rainfall' = 'Rainfall(mm)',
         'snowfall' = 'Snowfall (cm)',
         'seasons' = 'Seasons',
         'holiday' = 'Holiday',
         'functioning_day' = 'Functioning Day')
```


Step 6. Now we perform summary statistics. 

First we perform numerical summaries for quantitative variables without grouping by any categorical variables. We can copy the code from step 2 since we did this already. Note `range.1` is the minimum and `range.2` is the maximum, respectively, of an observation. 

```{r}
rentals_numeric <- rentals |>
  select(where(is.numeric)) |>
  as.matrix()

data.frame('mean' = colMeans(rentals_numeric),
'median' = colMedians(rentals_numeric),
'sd' = colSds(rentals_numeric),
'IQR' = colIQRs(rentals_numeric),
'range' = colRanges(rentals_numeric)) |>
  round(1) 
```

Next we create one- and two-way contingency tables to summarize our categorical variables.

```{r}
table(rentals$seasons)
table(rentals$holiday)
table(rentals$functioning_day)
table(rentals$seasons, rentals$holiday)
table(rentals$seasons, rentals$functioning_day)
table(rentals$holiday, rentals$functioning_day)
```

Next we will create numerical summaries for the Bike Rental Count across the different categorical variables. We will do it separately for each categorical variable. Then we do it grouped by all categorical variables as once. 

```{r}
rentals |>
  group_by(functioning_day) |>
  summarize(across(rented_bike_count,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()

rentals |>
  group_by(seasons) |>
  summarize(across(rented_bike_count,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()

rentals |>
  group_by(holiday) |>
  summarize(across(rented_bike_count,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()

rentals |>
  group_by(functioning_day, seasons, holiday) |>
  summarize(across(rented_bike_count,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()
            
```

As an example of what we can do with this information, we note that Rented Bike Counts are highest during the summer, and that in the summer the count doesn't seem to be affected by whether the day is a holiday, as long as it is a functioning day. 

We see from the output that no bikes are rented when the Functioning Day variable takes a value of 'No'. Therefore it makes sense to remove these observations from the tibble, since in this homework the response variable we are interested in is the Rented Bike Count.

```{r}
rentals <- rentals |>
  filter(functioning_day != 'No')
```

Now we use the subsetted data for the rest of the homework.


Step 7. In this step, we create a new data tibble by summarizing across all hours of the day. This will simplify the data since each date will have one observation. The new tibble will not have an hours column since we are summarizing across the whole day, and it will not have a Functioning Day column since we removed the "No" observations previously, so all remaining values are "Yes" observations. 

```{r}
rentals_condensed <- rentals |> 
  group_by(date, seasons, holiday) |>
  mutate(bike_count_daily = sum(rented_bike_count),
         rainfall_daily = sum(rainfall),
         snowfall_daily = sum(snowfall),
         temp_mean = mean(temperature),
         humidity_mean = mean(humidity),
         wind_speed_mean = mean(wind_speed),
         visibility_mean = mean(visibility),
         dew_point_temp_mean = mean(dew_point_temp),
         solar_radiation_mean = mean(solar_radiation)) |>
  select(date, seasons, holiday, bike_count_daily, rainfall_daily, snowfall_daily, temp_mean, humidity_mean, wind_speed_mean, visibility_mean, dew_point_temp_mean, solar_radiation_mean) |>
  unique() |>
  ungroup()
```

We can view the first few rows to get a feel for our new data table.

```{r}
head(as.data.frame(rentals_condensed))
```

Step 8. We will redo basic summary stats with the new data, and we make some plots to explore the data. First we determine the summary stats without grouping by any categorical variables.

```{r}
rentals_condensed_numeric <- rentals_condensed |>
  select(where(is.numeric)) |>
  as.matrix()

data.frame('mean' = colMeans(rentals_condensed_numeric),
'median' = colMedians(rentals_condensed_numeric),
'sd' = colSds(rentals_condensed_numeric),
'IQR' = colIQRs(rentals_condensed_numeric),
'range' = colRanges(rentals_condensed_numeric)) |>
  round(1) 
```

Next we determine the summary stats for daily bike rental count with grouping by categorical variables as we did in Step 6. Since we removed the Functional Day variable for reasons discussed above, we will not include this in the grouping.

```{r}
rentals_condensed |>
  group_by(seasons) |>
  summarize(across(bike_count_daily,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()

rentals_condensed |>
  group_by(holiday) |>
  summarize(across(bike_count_daily,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()

rentals_condensed |>
  group_by(seasons, holiday) |>
  summarize(across(bike_count_daily,
            list('mean' = ~mean(.x),
                 'median' = ~median(.x),
                 'sd' = ~sd(.x),
                 'IQR' = ~IQR(.x),
                 'min' = ~min(.x),
                 'max' = ~max(.x)),
            .names = "{.col}_{.fn}")) |>
  as.data.frame()
```

An interesting observation from this output is that in the Spring, mean daily bike rental count is lower on holidays than on non-holidays. However, in the summer, the mean daily bike rental count appears to be nearly the same on holidays and non-holidays. While we would need to conduct hypothesis testing to be more confident about this relationship, it seems that holidays which occur during the summer don't dissuade people from renting bikes, whereas holidays which occur in the spring do dissuade people from renting bikes. 

Next we create some plots. An interesting start would be to summarize graphically what we discussed in the previous paragraph and view the summaries of daily bike rental counts by season and holidays.

```{r}
rentals_condensed |>
  ggplot(aes(x = holiday, y = bike_count_daily)) + geom_boxplot() + facet_wrap(~seasons) + labs(x = 'Holiday Status', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count Summaries by Holiday Status and Season')
```

This depicts graphically what we noted from the numerical summaries. In the spring, fewer rentals occur on holidays, while in the summer, the difference between holidays and non-holidays is less pronounced. 

Next we will view daily bike rental counts over the course of the year.

```{r}
rentals_condensed |>
  ggplot(aes(x = date, y = bike_count_daily)) + geom_point() + labs(x = 'Date', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count by Date')
```

We see from the output that far fewer rentals occur in the winter, they start to rise around March-April, and they peak around July. Then there is another peak in the fall around October. It is also interesting to note that the variability in rentals is higher in the peak seasons and lower in the winter. These results make intuitive sense. Summer and Fall are nice times to ride. The winter can be uncomfortable.

In that spirit, we next make a plot of temperature versus rental count. We would expect in general that bike rental counts are higher on warmer days. Let's see.

```{r}
rentals_condensed |>
  ggplot(aes(x = temp_mean, y = bike_count_daily)) + geom_point() + labs(x = 'Average Daily Temperature', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count vs. Average Daily Temperature')
```

As expected, we see that bike rental counts tend to be higher on warmer days. However, we do see that at the high extreme of temperature, rentals start to decline. People are less likely to ride when it is too hot.

Finally let's take a look at correlation between numeric variables. We will view the results in a correlation matrix for easy viewing. 

```{r}
ggcorrplot(cor(rentals_condensed_numeric))
```

These correlations make sense. As discussed before based on our plot, daily bike rental count correlates positively with average daily temperature. And as one would expect, daily bike rental count correlates negatively with average wind speed, daily rainfall, and daily snowfall.  


## Splitting Data

Now that we have wrangled the data and done some EDA, it is time to begin modeling. In this section we split the data into training and test sets using a 75/25 split, stratifying on the seasons variable.

```{r}
rentals_condensed_split <- initial_split(rentals_condensed, prop = 0.75, strata = seasons)
rentals_condensed_train <- training(rentals_condensed_split)
rentals_condensed_test <- testing(rentals_condensed_split)
```

Now on the training set, we create a 10-fold CV split. 

```{r}
rentals_10_fold <- vfold_cv(rentals_condensed_train, 10)
```

  
## Fitting Three MLR Models

In this section, we fit 3 MLR models on the training data using 10-fold cross validation and pick a best model on the training data.

We begin by creating 3 recipes as outlined in the homework instructions. For the first recipe we use the date variable to create a weekend/weekday categorical (factor) variable which replaces the date variable, standardize the numeric variables, and create dummy variables for the categorical variables (seasons, holiday, and new weekend/weekday variable). First we will use `prep()` and `bake()` to print the transformed data as a sanity check. 

```{r}
recipe(bike_count_daily ~., data = rentals_condensed_train) |>
  step_date(date, features = 'dow') |>
  step_mutate(weekend = factor(ifelse(
    date_dow %in% c('Sat', 'Sun'),
    'Yes',
    'No'
  ))) |>
  step_rm(date_dow) |>
  update_role(date, new_role = 'Date') |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(holiday, seasons, weekend) |>
  prep(training = rentals_condensed) |>
  bake(rentals_condensed) 
```

The result looks good, so we save the recipe in a recipe object, which is what we actually need for fitting the model.

```{r}
rentals_rec1 <- recipe(bike_count_daily ~., data = rentals_condensed_train) |>
  step_date(date, features = 'dow') |>
  step_mutate(weekend = factor(ifelse(
    date_dow %in% c('Sat', 'Sun'),
    'Yes',
    'No'
  ))) |>
  step_rm(date_dow) |>
  update_role(date, new_role = 'Date') |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(holiday, seasons, weekend)
```

To create the second recipe, we use the same steps as above but we add in interaction terms between seasons and holiday, seasons and temperature, and temperature and rainfall.

```{r}
rentals_rec2 <- recipe(bike_count_daily ~., data = rentals_condensed_train) |>
  step_date(date, features = 'dow') |>
  step_mutate(weekend = factor(ifelse(
    date_dow %in% c('Sat', 'Sun'),
    'Yes',
    'No'
  ))) |>
  step_rm(date_dow) |>
  update_role(date, new_role = 'Date') |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(holiday, seasons, weekend) |>
  step_interact(terms = ~ starts_with('seasons'):holiday_No.Holiday + starts_with('seasons'):temp_mean + temp_mean:rainfall_daily) 
```

Finally, for the third recipe, we do the same as for the second recipe but add in quadratic terms for each numeric predictor.

```{r}
rentals_rec3 <- recipe(bike_count_daily ~., data = rentals_condensed_train) |>
  step_date(date, features = 'dow') |>
  step_mutate(weekend = factor(ifelse(
    date_dow %in% c('Sat', 'Sun'),
    'Yes',
    'No'
  ))) |>
  step_rm(date_dow) |>
  update_role(date, new_role = 'Date') |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_poly(all_numeric(), -all_outcomes()) |>
  step_dummy(holiday, seasons, weekend) |>
  step_interact(terms = ~ starts_with('seasons'):holiday_No.Holiday + starts_with('seasons'):temp_mean_poly_1 + temp_mean_poly_1:rainfall_daily_poly_1) 
  
```

Now we set up the model using the linear model engine and use `fit_resamples()` to fit the models.

```{r}
rentals_mod <- linear_reg() %>% 
  set_engine('lm')

rentals_CV_wkfl1 <- workflow() |>
  add_recipe(rentals_rec1) |>
  add_model(rentals_mod) 

rentals_CV_wkfl2 <- workflow() |>
  add_recipe(rentals_rec2) |>
  add_model(rentals_mod) 

rentals_CV_wkfl3 <- workflow() |>
  add_recipe(rentals_rec3) |>
  add_model(rentals_mod) 

rentals_CV_fit1 <- fit_resamples(rentals_CV_wkfl1, rentals_10_fold)

rentals_CV_fit2 <- fit_resamples(rentals_CV_wkfl2, rentals_10_fold)

rentals_CV_fit3 <- fit_resamples(rentals_CV_wkfl3, rentals_10_fold)

```

Finally, we can view the training set metrics for each model to compare models and determine which to use for the final fitting.

```{r}
rbind(rentals_CV_fit1 |> collect_metrics(),
      rentals_CV_fit2 |> collect_metrics(),
      rentals_CV_fit3 |> collect_metrics())
```

We see that the third model has the lowest training set RMSE, so we will choose this as our optimal model. We fit this model to the whole training set in the next step. 

## Fitting and Testing Best Model

Now that we have chosen the 'best' model (the third) as the one with the lowest training set RMSE, we fit this model to the full training set and print the test set RMSE.

```{r}
rentals_fit_final <- rentals_CV_wkfl3 |>
  last_fit(rentals_condensed_split)

rentals_fit_final |>
  collect_metrics()
```

We also obtain the final table of coefficients for the model. 

```{r}
rentals_fit_final |>
  extract_fit_parsnip()  |>
  tidy() |>
  print(n = 30)
```

